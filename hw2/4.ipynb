{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c168b7a8",
   "metadata": {},
   "source": [
    "# **ЗАДАНИЕ 4** - ПРИМЕНЕНИЕ КАСТОМНЫХ АУГМЕНТАЦИЙ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeeb2c6",
   "metadata": {},
   "source": [
    "## 1. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "931a0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2874d79",
   "metadata": {},
   "source": [
    "## 2. Дублируем классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fde7b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransform:\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "        # вызывает трансформацию с вероятностью p\n",
    "        if random.random() < self.p:\n",
    "            return self.apply(img)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def apply(self, img: Image.Image) -> Image.Image:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d1f8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(BaseTransform):\n",
    "    def __init__(self, p: float = 0.5, crop_size=(50, 50)):\n",
    "        super().__init__(p)\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def apply(self, img: Image.Image) -> Image.Image:\n",
    "        w, h = img.size\n",
    "        cw, ch = self.crop_size\n",
    "        if cw > w or ch > h:\n",
    "            return img  # если crop больше исходного, то возвращаем оригинал\n",
    "\n",
    "        left = random.randint(0, w - cw)\n",
    "        top = random.randint(0, h - ch)\n",
    "        right = left + cw\n",
    "        bottom = top + ch\n",
    "        return img.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f314aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotate(BaseTransform):\n",
    "    def __init__(self, p: float = 0.5, max_angle: float = 30):\n",
    "        super().__init__(p)\n",
    "        self.max_angle = max_angle\n",
    "\n",
    "    def apply(self, img: Image.Image) -> Image.Image:\n",
    "        angle = random.uniform(-self.max_angle, self.max_angle)\n",
    "        return img.rotate(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84c56128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(BaseTransform):\n",
    "    def __init__(self, size=(28, 28)):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return F.resize(img, self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c819b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomZoom(BaseTransform):\n",
    "    def __init__(self, p: float = 0.5, zoom_range=(0.8, 1.2)):\n",
    "        super().__init__(p)\n",
    "        self.zoom_range = zoom_range\n",
    "\n",
    "    def apply(self, img: Image.Image) -> Image.Image:\n",
    "        zoom = random.uniform(*self.zoom_range)\n",
    "        w, h = img.size\n",
    "        new_w, new_h = int(w * zoom), int(h * zoom)\n",
    "        img_zoomed = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "        # увеличили - обрезаем\n",
    "        # уменьшили - добавляем поля\n",
    "        if zoom > 1:\n",
    "            left = (new_w - w) // 2\n",
    "            top = (new_h - h) // 2\n",
    "            img_zoomed = img_zoomed.crop((left, top, left + w, top + h))\n",
    "        else:\n",
    "            pad_w = (w - new_w) // 2\n",
    "            pad_h = (h - new_h) // 2\n",
    "            new_img = Image.new(\"RGB\", (w, h))\n",
    "            new_img.paste(img_zoomed, (pad_w, pad_h))\n",
    "            img_zoomed = new_img\n",
    "\n",
    "        return img_zoomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139b37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, img: Image.Image) -> torch.Tensor:\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        if arr.ndim == 2:\n",
    "            arr = np.expand_dims(arr, axis=-1)\n",
    "        # HWC -> CHW\n",
    "        arr = np.transpose(arr, (2, 0, 1))\n",
    "        return torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4506de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "            if isinstance(img, Image.Image) and img.mode != 'L':\n",
    "                img = img.convert('L')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9849d8",
   "metadata": {},
   "source": [
    "## 3. Настрйока TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee35e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "logdir_base = \"runs/fashion_augment_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589258e1",
   "metadata": {},
   "source": [
    "## 4. Определяем разные трансформации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87ee7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_aug = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "mild_aug = Compose([\n",
    "    RandomCrop(p=0.3, crop_size=(24, 24)),\n",
    "    RandomRotate(p=0.3, max_angle=15),\n",
    "    RandomZoom(p=0.3, zoom_range=(0.9, 1.1)),\n",
    "    Resize((28, 28)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "strong_aug = Compose([\n",
    "    RandomCrop(p=0.8, crop_size=(24, 24)),\n",
    "    RandomRotate(p=0.8, max_angle=30),\n",
    "    RandomZoom(p=0.8, zoom_range=(0.8, 1.2)),\n",
    "    Resize((28, 28)),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed1348",
   "metadata": {},
   "source": [
    "## 5. FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa2df7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(transform, batch_size=64):\n",
    "    train_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "    return (\n",
    "        DataLoader(train_data, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac46d12",
   "metadata": {},
   "source": [
    "## 6. Простая CNN модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602cf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2440a12",
   "metadata": {},
   "source": [
    "## 7. Функции обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2315e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, writer, epochs=10):\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            correct += (preds.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                preds = model(X)\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "                val_correct += (preds.argmax(1) == y).sum().item()\n",
    "                val_total += y.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "              f\"Train loss={train_loss:.4f}, acc={train_acc:.3f}, \"\n",
    "              f\"Val loss={val_loss:.4f}, acc={val_acc:.3f}\")\n",
    "\n",
    "        writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
    "        writer.add_scalars(\"Accuracy\", {\"train\": train_acc, \"val\": val_acc}, epoch)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78efff",
   "metadata": {},
   "source": [
    "## 8. Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b023eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Эксперимент: no_aug ===\n",
      "Epoch 1/10: Train loss=0.4998, acc=0.819, Val loss=0.3457, acc=0.872\n",
      "Epoch 2/10: Train loss=0.3246, acc=0.882, Val loss=0.2921, acc=0.895\n",
      "Epoch 3/10: Train loss=0.2815, acc=0.897, Val loss=0.2718, acc=0.900\n",
      "Epoch 4/10: Train loss=0.2529, acc=0.908, Val loss=0.2528, acc=0.908\n",
      "Epoch 5/10: Train loss=0.2267, acc=0.917, Val loss=0.2493, acc=0.906\n",
      "Epoch 6/10: Train loss=0.2074, acc=0.924, Val loss=0.2302, acc=0.914\n",
      "Epoch 7/10: Train loss=0.1913, acc=0.930, Val loss=0.2314, acc=0.917\n",
      "Epoch 8/10: Train loss=0.1732, acc=0.936, Val loss=0.2217, acc=0.921\n",
      "Epoch 9/10: Train loss=0.1608, acc=0.939, Val loss=0.2330, acc=0.918\n",
      "Epoch 10/10: Train loss=0.1493, acc=0.944, Val loss=0.2283, acc=0.921\n",
      "\n",
      "=== Эксперимент: mild_aug ===\n",
      "Epoch 1/10: Train loss=0.6292, acc=0.763, Val loss=0.3796, acc=0.859\n",
      "Epoch 2/10: Train loss=0.4526, acc=0.832, Val loss=0.3356, acc=0.876\n",
      "Epoch 3/10: Train loss=0.4050, acc=0.848, Val loss=0.3216, acc=0.882\n",
      "Epoch 4/10: Train loss=0.3804, acc=0.856, Val loss=0.2829, acc=0.897\n",
      "Epoch 5/10: Train loss=0.3597, acc=0.865, Val loss=0.2755, acc=0.899\n",
      "Epoch 6/10: Train loss=0.3385, acc=0.873, Val loss=0.2559, acc=0.908\n",
      "Epoch 7/10: Train loss=0.3243, acc=0.880, Val loss=0.2614, acc=0.904\n",
      "Epoch 8/10: Train loss=0.3087, acc=0.884, Val loss=0.2474, acc=0.909\n",
      "Epoch 9/10: Train loss=0.3028, acc=0.887, Val loss=0.2431, acc=0.912\n",
      "Epoch 10/10: Train loss=0.2942, acc=0.890, Val loss=0.2345, acc=0.913\n",
      "\n",
      "=== Эксперимент: strong_aug ===\n",
      "Epoch 1/10: Train loss=0.8953, acc=0.659, Val loss=0.5652, acc=0.782\n",
      "Epoch 2/10: Train loss=0.6693, acc=0.743, Val loss=0.4965, acc=0.805\n",
      "Epoch 3/10: Train loss=0.6150, acc=0.766, Val loss=0.4723, acc=0.812\n",
      "Epoch 4/10: Train loss=0.5819, acc=0.778, Val loss=0.4141, acc=0.847\n",
      "Epoch 5/10: Train loss=0.5485, acc=0.792, Val loss=0.3923, acc=0.856\n",
      "Epoch 6/10: Train loss=0.5286, acc=0.803, Val loss=0.3837, acc=0.860\n",
      "Epoch 7/10: Train loss=0.5056, acc=0.808, Val loss=0.3624, acc=0.865\n",
      "Epoch 8/10: Train loss=0.4957, acc=0.813, Val loss=0.3739, acc=0.860\n",
      "Epoch 9/10: Train loss=0.4798, acc=0.820, Val loss=0.3524, acc=0.871\n",
      "Epoch 10/10: Train loss=0.4713, acc=0.825, Val loss=0.3277, acc=0.878\n",
      "Обучение всех экспериментов завершено. Запустите TensorBoard для просмотра:\n",
      "tensorboard --logdir=runs\n"
     ]
    }
   ],
   "source": [
    "experiments = {\n",
    "    \"no_aug\": no_aug,\n",
    "    \"mild_aug\": mild_aug,\n",
    "    \"strong_aug\": strong_aug,\n",
    "}\n",
    "\n",
    "for name, transform in experiments.items():\n",
    "    print(f\"\\n=== Эксперимент: {name} ===\")\n",
    "    writer = SummaryWriter(log_dir=f\"{logdir_base}/{name}\")\n",
    "\n",
    "    train_loader, test_loader = get_dataloaders(transform)\n",
    "    model = train_model(train_loader, test_loader, writer, epochs=10)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "print(\"Обучение всех экспериментов завершено. Запустите TensorBoard для просмотра:\")\n",
    "print(\"tensorboard --logdir=runs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spbu-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
